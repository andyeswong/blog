{
  "id": "010-paradigma-agentic-ai-funciones-tool-calling-correccion",
  "title": "El nuevo paradigma Agentic AI: programación para IA, tool calling y autocorrección en agentes",
  "slug": "nuevo-paradigma-agentic-ai-funciones-tool-calling-correccion",
  "description": "Analizamos cómo programamos para IA que invoca funciones IA, diferenciamos LLMs como funciones y tool calling, y explicamos el autocorrector en agentes Agentic AI.",
  "image_url": "/img/agentic.jpg",
  "tags": [
    "agentic ai",
    "funciones ia",
    "tool calling",
    "autocorreccion ia",
    "dify platform",
    "llm",
    "workflows ia",
    "programacion avanzada"
  ],
  "author": "AWONG",
  "reading_time": 10,
  "content": "<article>\n<h1>El nuevo paradigma Agentic AI: programación para IA, tool calling y autocorrección en agentes</h1>\n\n<p>Recientemente, en la conferencia FronteraFutura, conversaba con colegas sobre el cambio radical que enfrentamos como desarrolladores con la llegada de Agentic AI. En mi equipo tenemos dos desarrolladores especializados en IA y constatamos que ya no programamos para humanos, sino que diseñamos funciones para que modelos LLM las invoquen y respondan al usuario final.</p>\n\n<p>Una plataforma que ejemplifica este paradigma es <strong>Dify</strong>, donde las funciones para agentes se crean mediante workflows que combinan código y modelos LLM. Esto significa que tenemos IA (agentes) que invocan funciones que a su vez utilizan IA como función. Por ejemplo, la función <em>Parameter Extractor</em> es un LLM configurado para extraer parámetros estructurados siguiendo instrucciones precisas.</p>\n\n<h2>¿Qué es Agentic AI y cómo se diferencia de un chatbot?</h2>\n<p>Agentic AI son agentes inteligentes capaces de tomar decisiones autónomas, planificar, ejecutar múltiples pasos y adaptarse mediante aprendizaje continuo. A diferencia de un chatbot clásico, que solo responde texto plano, un agente IA puede invocar funciones, interactuar con herramientas externas y corregirse a sí mismo para mejorar resultados. Los chatbots son reactivos y limitados a interacciones lineales, mientras que los agentes Agentic AI son proactivos y modulares.</p>\n\n<h2>Uso de LLMs como funciones programables</h2>\n<p>En este paradigma, los LLMs dejan de ser solo generadores de texto para convertirse en funciones programables que reciben múltiples parámetros, contexto y estado, y devuelven respuestas estructuradas en formatos como JSON para su fácil interpretación automática.</p>\n<pre><code>{\n 'function_call': 'extract_parameters',\n 'arguments': {\n 'user_name': 'Ana Pérez',\n 'request': 'Estado del proyecto',\n 'priority': 'alta'\n }\n}\n</code></pre>\n<p>Este formato es crucial para que otros agentes o sistemas puedan parsear el resultado y continuar con flujos automatizados sin ambigüedad.</p>\n\n<h2>Diferencia con Tool Calling</h2>\n<p><strong>LLMs como funciones</strong> se refiere a usar modelos de lenguaje como bloques funcionales que procesan y devuelven datos dentro del sistema. <strong>Tool calling</strong> es la capacidad del agente para invocar herramientas externas o APIs, permitiendo ampliar sus capacidades para tareas específicas.</p>\n<p>Estos dos conceptos pueden coexistir: un agente puede usar LLMs programables internamente y además llamar herramientas externas mediante tool calling para resolver problemas complejos.</p>\n\n<h2>El ciclo de autocorrección en agentes IA</h2>\n<p>Una característica poderosa de los agentes Agentic AI es su habilidad para invocar funciones, detectar errores y corregirse autónomamente. Si una función llamada genera un resultado incorrecto o subóptimo, el agente puede:</p>\n<ul>\n <li>Detectar el error mediante excepciones, códigos o resultados inesperados.</li>\n <li>Reflexionar y analizar lo que salió mal.</li>\n <li>Modificar su plan o inputs para llamar nuevamente a la función con parámetros ajustados.</li>\n</ul>\n<p>Esto genera bucles de retroalimentación que permiten una mejora continua sin intervención humana directa.</p>\n\n<h2>Ejemplo de función IA retornando JSON y ciclo autocorrectivo</h2>\n<pre><code>{\n 'role': 'system',\n 'text': 'Eres un agente IA que extrae parámetros y llama a funciones. Si detectas error, corrígelo y vuelve a intentar.',\n 'function_call': 'extract_parameters',\n 'arguments': {\n 'input_text': 'Quiero reservar una cita con Carlos el viernes a las 10am',\n 'criteria': ['nombre', 'fecha', 'hora']\n },\n 'on_error': {\n 'action': 'retry',\n 'adjustment': 'Cambiar la fecha a sábado si viernes no está disponible'\n }\n}\n</code></pre>\n\n<p>En este caso, el agente primero extrae parámetros, si reserva no es posible, ajusta y vuelve a llamar a la función para lograr el objetivo.</p>\n\n</article>",
  "metadata": {
    "created_time": "2025-11-27T22:55:00Z",
    "modification_time": "2025-11-27T06:53:54.737Z",
    "version": "1.0",
    "status": "published",
    "seo_keywords": "agentic ai, funciones ia, llm como funciones, tool calling, autocorreccion ia, workflows ia, dify platform, programación avanzada"
  },
  "featured": true,
  "views": 1
}