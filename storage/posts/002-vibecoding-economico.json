{
  "id": "002-vibecoding-economico",
  "title": "Vibecoding Económico: Cómo Hago Desarrollo Asistido por IA sin Arruinarme",
  "slug": "vibecoding-economico",
  "description": "Una guía práctica sobre cómo optimizar costos en el desarrollo asistido por IA utilizando Cline con DeepSeek para planificación y Claude Haiku para ejecución, logrando un flujo de trabajo real y sostenible.",
  "image_url": "/img/vibecoding_economico.jpg",
  "tags": [
    "vibecoding",
    "cline",
    "deepseek",
    "claude haiku",
    "ai coding",
    "cost optimization",
    "vscode",
    "llm"
  ],
  "author": "AWONG",
  "reading_time": 12,
  "content": "<article class=\"prose prose-invert\"><h1>Vibecoding Económico: Cómo Hago Desarrollo Asistido por IA sin Arruinarme</h1><p>El vibecoding prometía revolucionar cómo escribimos código: dejar de teclear línea por línea y delegar al LLM. La realidad es diferente. Después de meses forzándome a adoptar este flujo de trabajo, me encontré con un muro que muchos conocen: el contexto y los costos. Claude es indiscutiblemente el mejor modelo para generación de código, pero usarlo de forma sostenible parecía imposible... hasta que encontré una técnica que cambió todo.</p><h2>El Problema Real del Vibecoding</h2><p>Si has intentado hacer vibecoding como flujo de trabajo real, probablemente conoces esta frustración: con la suscripción Pro de Claude ($20 USD/mes), después de 10 o 15 prompts te quedas bloqueado por 4 horas. Imagina trabajar 30 minutos cada 4 horas. Por más que los LLMs faciliten el trabajo, con ese ritmo no se logra nada productivo.</p><p>El problema no es solo el límite de mensajes. Es la combinación de factores que hacen insostenible el vibecoding tradicional:</p><ul><li><strong>Límites de contexto:</strong> Cada modelo tiene un tope de tokens que puede procesar, y los proyectos reales superan esos límites rápidamente.</li><li><strong>Costo por token:</strong> Los mejores modelos de coding son también los más caros, y el vibecoding consume tokens de forma agresiva.</li><li><strong>Pérdida de tiempo:</strong> Si no entiendes qué está haciendo el LLM o con qué tecnologías trabaja, el vibecoding te retrasa más de lo que te ayuda.</li></ul><p>Entonces, ¿cómo logré hacer vibecoding de forma eficiente y con costos realmente bajos? La respuesta está en un stack específico y una técnica de división de trabajo.</p><h2>El Stack: VSCode + Cline + DeepSeek + Claude Haiku</h2><h3>¿Qué es Cline?</h3><p>Cline es una extensión open-source para VSCode que funciona como un agente de IA autónomo dentro de tu IDE. A diferencia de herramientas de autocompletado como Copilot, Cline puede crear y editar archivos, ejecutar comandos en terminal, navegar en el browser, y más, todo con tu permiso en cada paso.</p><p>Lo que hace especial a Cline es su arquitectura client-side: tu código nunca pasa por servidores externos. Usas tus propias API keys y pagas directamente a los proveedores. Esto significa control total sobre costos, modelos, y privacidad.</p><p>Cline soporta múltiples proveedores de API: OpenRouter, Anthropic, OpenAI, Google Gemini, AWS Bedrock, y modelos locales a través de Ollama o LM Studio. Esta flexibilidad es clave para la técnica que voy a explicar.</p><h3>La Característica Clave: Plan y Act Mode</h3><p>Cline tiene una funcionalidad que divide el trabajo en dos modos distintos:</p><ul><li><strong>Plan Mode:</strong> El agente actúa como arquitecto. Lee archivos, analiza código, investiga documentación, genera planes y hace debug. Básicamente, tiene acceso a herramientas de lectura pero no puede modificar nada.</li><li><strong>Act Mode:</strong> El agente ejecuta. Crea archivos, edita código, elimina archivos, ejecuta comandos de terminal. Tiene todas las herramientas habilitadas.</li></ul><p>Descubrí esta distinción de forma curiosa: una vez, el LLM me respondió en modo Plan diciendo algo como \"veo que no tengo acceso a todas las herramientas, solo puedo leer\". Esa limitación es precisamente lo que hace posible la optimización de costos.</p><p>Lo más importante: desde la versión 3.2.6, Cline permite configurar diferentes modelos para cada modo. Puedes usar un modelo para planificación y otro completamente diferente para ejecución.</p><h2>La Técnica: DeepSeek para Plan, Claude Haiku para Act</h2><p>Aquí está el núcleo de mi estrategia. La planificación consume muchos tokens porque implica leer código existente, analizar estructuras, investigar documentación y generar planes detallados. La ejecución, en cambio, son acciones concretas y específicas.</p><h3>Paso 1: Planificación con DeepSeek</h3><p>DeepSeek es absurdamente barato. Los precios actuales de la API son aproximadamente $0.07 por millón de tokens de input (con cache hit) y $0.56 por millón de tokens de input (cache miss), con outputs alrededor de $1.68 por millón de tokens. Comparado con otros modelos, estamos hablando de costos 10-30 veces menores.</p><p>Para la fase de planificación, donde el LLM lee todo tu codebase, analiza patrones, y genera un plan detallado de implementación, DeepSeek es perfecto. Puede consumir miles de tokens leyendo archivos y pensando, y el costo sigue siendo mínimo.</p><h3>Paso 2: Ejecución con Claude Haiku 3.5</h3><p>Una vez que el plan está listo y todo el contexto ha sido procesado, cambio a modo Act con Claude Haiku 3.5. Este modelo cuesta $0.80 por millón de tokens de input y $4 por millón de tokens de output. No es tan barato como DeepSeek, pero es significativamente más económico que Claude Sonnet ($3/$15) o Claude Opus ($15/$75).</p><p>¿Por qué Claude Haiku y no seguir con DeepSeek? Porque para la ejecución real de código, la familia Claude sigue siendo superior. Haiku 3.5 ofrece capacidades de coding de nivel casi-frontera a una fracción del costo de los modelos premium. Es el balance perfecto entre calidad y precio para la fase de ejecución.</p><h3>El Flujo Completo</h3><pre><code>1. Configuro Cline con DeepSeek en Plan Mode\n2. Le pido que analice el codebase y genere un plan\n3. DeepSeek lee archivos, investiga, genera el plan detallado\n   (Costo: ~$0.01-0.05 por sesión de planificación)\n4. Reviso el plan y ajusto si es necesario\n5. Cambio a Act Mode con Claude Haiku 3.5\n6. Ejecuto el plan paso a paso\n   (Costo: ~$0.05-0.20 por sesión de ejecución)\n\nTotal por feature típica: $0.10-0.30</code></pre><h2>Configuración Práctica en Cline</h2><p>Para implementar esta técnica, necesitas configurar Cline para usar modelos diferentes en cada modo. Ve a la configuración de Cline y habilita la opción \"Use different models for Plan and Act modes\". Luego configura cada modo por separado:</p><pre><code>// Configuración Plan Mode\nAPI Provider: DeepSeek (o OpenRouter con DeepSeek)\nModel: deepseek-chat o deepseek-v3\n\n// Configuración Act Mode\nAPI Provider: Anthropic\nModel: claude-3.5-haiku</code></pre><p>Cline recuerda estas preferencias globalmente, así que no tienes que reconfigurar en cada sesión. El sistema mantiene el contexto de la conversación al cambiar entre modos, permitiendo una transición fluida de planificación a ejecución.</p><h2>Comparación de Costos</h2><p>Para poner los números en perspectiva, comparemos diferentes enfoques para un día típico de desarrollo con vibecoding (asumiendo ~5 millones de tokens procesados entre input y output):</p><pre><code>Enfoque tradicional con Claude Sonnet:\n- Input: 3M tokens × $3/1M = $9\n- Output: 2M tokens × $15/1M = $30\n- Total: ~$39/día\n\nMi técnica (DeepSeek Plan + Haiku Act):\n- Plan (DeepSeek): 2M tokens × $0.56/1M = $1.12\n- Act Input (Haiku): 1M tokens × $0.80/1M = $0.80\n- Act Output (Haiku): 2M tokens × $4/1M = $8\n- Total: ~$10/día\n\nAhorro: ~75%</code></pre><p>Y esto asumiendo uso intensivo. En días normales, mis costos están entre $2-5 USD. Eso es menos de lo que cuesta un café.</p><h2>Consideraciones Importantes</h2><p>Esta técnica no es magia. Hay algunas cosas que debes tener en cuenta:</p><ul><li><strong>Requiere entender el proceso:</strong> El vibecoding funciona mejor cuando entiendes qué está haciendo el LLM. Si no comprendes las tecnologías involucradas, aún puedes perderte.</li><li><strong>La planificación es crucial:</strong> Un buen plan en modo DeepSeek reduce dramáticamente los tokens necesarios en modo ejecución. Invierte tiempo en refinar el plan antes de ejecutar.</li><li><strong>Monitorea el contexto:</strong> Cline muestra una barra de progreso del context window. Mantén un ojo en ella para no perder contexto importante en tareas largas.</li><li><strong>Aprovecha el cache:</strong> DeepSeek tiene descuentos significativos por cache hit. Si reutilizas prompts o instrucciones de sistema, tus costos bajan aún más.</li></ul><h2>Conclusión</h2><p>El vibecoding como flujo de trabajo real es posible, pero requiere estrategia. La combinación de Cline con su sistema Plan/Act, DeepSeek para la fase de investigación y planificación, y Claude Haiku para la ejecución, crea un stack que es tanto poderoso como económico.</p><p>No estás limitado a 30 minutos de trabajo cada 4 horas. No necesitas elegir entre el mejor modelo y tu presupuesto. Con la configuración correcta, puedes tener un copiloto de IA funcionando todo el día por el costo de un par de cafés a la semana.</p><p>El secreto está en usar el modelo correcto para cada fase del trabajo. DeepSeek para pensar, Claude Haiku para hacer. Simple, efectivo, y sostenible.</p></article>",
  "metadata": {
    "created_time": "2025-11-19T10:00:00Z",
    "modification_time": "2025-11-20T18:59:42.408Z",
    "version": "1.0",
    "status": "published",
    "seo_keywords": "vibecoding, cline vscode, deepseek api, claude haiku, ai coding costs, llm optimization, plan act mode, coding assistant, development workflow, token optimization"
  },
  "featured": true,
  "views": 4
}