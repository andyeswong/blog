{
  "id": "003-toon-compresion-contexto",
  "title": "TOON: La Notación que Reduce tus Tokens hasta un 60% en Prompts de LLM",
  "slug": "toon-compresion-contexto",
  "description": "Un análisis técnico de TOON (Token-Oriented Object Notation), el formato que combina la legibilidad de YAML con la eficiencia de CSV para optimizar el contexto en desarrollo asistido por IA.",
  "image_url": "https://images.pexels.com/photos/5926382/pexels-photo-5926382.jpeg",
  "tags": [
    "toon",
    "context compression",
    "llm",
    "tokens",
    "json",
    "yaml",
    "ai coding",
    "cost optimization"
  ],
  "author": "AWONG",
  "reading_time": 12,
  "content": "<article class=\"prose prose-invert\"><h1>TOON: La Notación que Reduce tus Tokens hasta un 60% en Prompts de LLM</h1><p>Hace algunos días, en una conversación con colegas entusiastas del vibe-coding y del desarrollo asistido por IA, surgió un tema recurrente: lo complicado que es manejar el contexto para optimizar costos. ¿Cómo mantener en un solo chat todo lo necesario para trabajar sin que el modelo pierda el hilo o sin que la factura se dispare? Entonces, uno de ellos mencionó TOON. Investigué, y lo que encontré podría cambiar cómo estructuramos datos para LLMs.</p><h2>El Problema: JSON es Verboso y los Tokens Cuestan</h2><p>Si trabajas con LLMs de forma intensiva, conoces esta realidad: los tokens cuestan dinero. Cada prompt que envías, cada respuesta que recibes, todo se traduce en tokens. Y el formato que usamos para estructurar datos tiene un impacto directo en ese consumo.</p><p>JSON es el estándar de facto para intercambio de datos, pero es extremadamente verboso. Las llaves, corchetes, comillas y la repetición constante de claves en arrays de objetos consumen tokens innecesariamente. Cuando trabajas con datasets grandes o necesitas incluir mucho contexto en tus prompts, esta verbosidad se convierte en un problema real de costos y límites de contexto.</p><h2>¿Qué es TOON?</h2><p>TOON (Token-Oriented Object Notation) es un formato de serialización diseñado específicamente para minimizar el consumo de tokens en prompts de LLM, manteniendo la legibilidad humana y la compatibilidad con el modelo de datos de JSON. Piensa en él como una capa de traducción: usas JSON programáticamente y lo codificas como TOON para la entrada del LLM.</p><h3>La Filosofía detrás de TOON</h3><p>TOON combina dos enfoques probados: la estructura basada en indentación de YAML para objetos anidados, y un layout tabular estilo CSV para arrays uniformes. El resultado es un formato que puede lograr reducciones del 30-60% en tokens comparado con JSON formateado, especialmente en arrays de objetos con la misma estructura.</p><h3>Características Principales</h3><ul><li><strong>Eficiencia en Tokens:</strong> Típicamente 30-60% menos tokens en arrays uniformes grandes comparado con JSON formateado.</li><li><strong>Guardrails para LLMs:</strong> Longitudes explícitas y campos declarados permiten validación estructural.</li><li><strong>Sintaxis Mínima:</strong> Elimina puntuación redundante (llaves, corchetes, la mayoría de las comillas).</li><li><strong>Estructura por Indentación:</strong> Como YAML, usa espacios en blanco en lugar de llaves.</li><li><strong>Arrays Tabulares:</strong> Declara las claves una vez y transmite los datos como filas.</li></ul><h2>Ejemplo Práctico: De JSON a TOON</h2><p>Veamos la transformación con un ejemplo real. Supongamos que tienes datos de métricas de analytics:</p><pre><code>// JSON Original (22,250 tokens)\n{\n  \"metrics\": [\n    {\n      \"date\": \"2025-01-01\",\n      \"views\": 5715,\n      \"clicks\": 211,\n      \"conversions\": 28,\n      \"revenue\": 7976.46,\n      \"bounceRate\": 0.47\n    },\n    {\n      \"date\": \"2025-01-02\",\n      \"views\": 7103,\n      \"clicks\": 393,\n      \"conversions\": 28,\n      \"revenue\": 8360.53,\n      \"bounceRate\": 0.32\n    }\n    // ... más filas\n  ]\n}</code></pre><p>El mismo dataset en formato TOON:</p><pre><code>// TOON (9,120 tokens - 59% de reducción)\nmetrics[5]{date,views,clicks,conversions,revenue,bounceRate}:\n  2025-01-01,5715,211,28,7976.46,0.47\n  2025-01-02,7103,393,28,8360.53,0.32\n  2025-01-03,7248,378,24,3212.57,0.5\n  2025-01-04,2927,77,11,1211.69,0.62\n  2025-01-05,3530,82,8,462.77,0.56</code></pre><p>Observa cómo TOON declara la estructura una sola vez: <code>metrics[5]{date,views,clicks,conversions,revenue,bounceRate}:</code> indica que hay 5 elementos con esos 6 campos. Luego, cada fila contiene solo los valores separados por comas. No hay repetición de claves, no hay llaves, no hay corchetes por cada objeto.</p><h2>Benchmarks: Los Números Hablan</h2><p>Los benchmarks de TOON son impresionantes y están respaldados por pruebas con múltiples modelos (Claude Haiku, Gemini Flash, GPT-5 Nano, Grok 4). Aquí está el resumen de rendimiento general:</p><pre><code>TOON ████████████████████ 26.9 │ 73.9% acc │ 2,744 tokens\nJSON compact █████████████████░░░ 22.9 │ 70.7% acc │ 3,081 tokens\nYAML ██████████████░░░░░░ 18.6 │ 69.0% acc │ 3,719 tokens\nJSON ███████████░░░░░░░░░ 15.3 │ 69.7% acc │ 4,545 tokens\nXML ██████████░░░░░░░░░░ 13.0 │ 67.1% acc │ 5,167 tokens</code></pre><p>TOON logra 73.9% de precisión (vs 69.7% de JSON) mientras usa 39.6% menos tokens. No solo es más eficiente en costo, sino que los LLMs lo comprenden mejor.</p><h3>Ahorros por Tipo de Estructura</h3><p>Para datos tabulares uniformes (registros de empleados, métricas de tiempo, repositorios), TOON logra reducciones del 42-60% comparado con JSON. Incluso para estructuras anidadas o semi-uniformes, los ahorros rondan el 15-33%.</p><h2>Cómo Funciona la Sintaxis</h2><h3>Objetos Simples</h3><p>Los objetos con valores primitivos se representan con indentación, similar a YAML:</p><pre><code>// JavaScript\n{ id: 123, name: 'Ada', active: true }\n\n// TOON\nid: 123\nname: Ada\nactive: true</code></pre><h3>Arrays Primitivos</h3><p>Los arrays de primitivos incluyen la longitud en corchetes:</p><pre><code>// JavaScript\n{ tags: ['admin', 'ops', 'dev'] }\n\n// TOON\ntags[3]: admin,ops,dev</code></pre><h3>Arrays Tabulares (El Poder Real)</h3><p>Cuando todos los objetos de un array comparten los mismos campos primitivos, TOON usa formato tabular:</p><pre><code>// JavaScript\n{\n  items: [\n    { sku: 'A1', qty: 2, price: 9.99 },\n    { sku: 'B2', qty: 1, price: 14.5 }\n  ]\n}\n\n// TOON\nitems[2]{sku,qty,price}:\n  A1,2,9.99\n  B2,1,14.5</code></pre><p>El header <code>items[2]{sku,qty,price}:</code> declara: 2 elementos, con campos sku, qty y price. Cada fila son los valores en ese orden. Esta declaración explícita ayuda a los LLMs a validar y parsear la estructura correctamente.</p><h3>Key Folding para Estructuras Anidadas</h3><p>TOON v1.5 introdujo key folding para colapsar cadenas de objetos de una sola clave en paths con puntos:</p><pre><code>// Sin key folding\ndata:\n  metadata:\n    items[2]: a,b\n\n// Con key folding\ndata.metadata.items[2]: a,b</code></pre><h2>Instalación y Uso</h2><p>TOON tiene un SDK oficial en TypeScript y una CLI para conversiones rápidas:</p><pre><code># Convertir JSON a TOON desde CLI\nnpx @toon-format/cli input.json -o output.toon\n\n# Pipe desde stdin\necho '{\"name\": \"Ada\", \"role\": \"dev\"}' | npx @toon-format/cli\n\n# Ver estadísticas de tokens\nnpx @toon-format/cli data.json --stats -o output.toon</code></pre><p>Para usar en tu código:</p><pre><code>import { encode, decode } from '@toon-format/toon'\n\nconst data = {\n  users: [\n    { id: 1, name: 'Alice', role: 'admin' },\n    { id: 2, name: 'Bob', role: 'user' }\n  ]\n}\n\n// Codificar a TOON\nconst toon = encode(data)\n// users[2]{id,name,role}:\n//   1,Alice,admin\n//   2,Bob,user\n\n// Decodificar de vuelta a JSON\nconst restored = decode(toon)</code></pre><h3>Opciones de Delimitadores</h3><p>TOON soporta diferentes delimitadores que pueden ofrecer ahorros adicionales:</p><pre><code>// Delimitador por tabs (más eficiente en tokens)\nencode(data, { delimiter: '\\t' })\n\n// Delimitador por pipes\nencode(data, { delimiter: '|' })</code></pre><h2>Cuándo Usar (y Cuándo No Usar) TOON</h2><h3>TOON Excela Con:</h3><ul><li><strong>Arrays uniformes de objetos:</strong> Datasets con la misma estructura repetida (logs, métricas, registros).</li><li><strong>Contexto de LLM:</strong> Cuando necesitas incluir mucho dato estructurado en un prompt.</li><li><strong>Optimización de costos:</strong> Proyectos donde el consumo de tokens impacta directamente el presupuesto.</li></ul><h3>Considera Alternativas Cuando:</h3><ul><li><strong>Estructuras profundamente anidadas:</strong> Con 0% de elegibilidad tabular, JSON compacto puede ser más eficiente.</li><li><strong>Datos puramente tabulares:</strong> CSV es más pequeño para tablas planas sin anidamiento.</li><li><strong>Aplicaciones críticas en latencia:</strong> Algunos setups (especialmente modelos locales) pueden procesar JSON más rápido a pesar del mayor conteo de tokens.</li></ul><h2>Integración con tu Flujo de Trabajo</h2><p>TOON se integra naturalmente con el stack de vibecoding económico que ya conocemos. Cuando usas Cline con DeepSeek para planificación, puedes codificar el contexto de tu codebase en TOON antes de enviarlo al LLM. Esto significa que puedes incluir más archivos, más estructura, más contexto en cada prompt sin explotar el límite de contexto o el presupuesto.</p><p>Para usar TOON efectivamente en prompts de LLM, la documentación recomienda mostrar el formato en lugar de describirlo:</p><pre><code>Data is in TOON format (2-space indent, arrays show length and fields).\n\n```toon\nusers[3]{id,name,role,lastLogin}:\n  1,Alice,admin,2025-01-15T10:30:00Z\n  2,Bob,user,2025-01-14T15:22:00Z\n  3,Charlie,user,2025-01-13T09:45:00Z\n```\n\nTask: Return only users with role \"user\" as TOON.</code></pre><h2>Implementaciones en Otros Lenguajes</h2><p>Además del SDK oficial en TypeScript, hay implementaciones comunitarias en desarrollo para Python, Go, Rust, .NET, Swift, Ruby, PHP, y muchos más. Esto significa que puedes integrar TOON en prácticamente cualquier stack de desarrollo.</p><h2>Conclusión</h2><p>TOON representa una solución elegante a un problema real del desarrollo asistido por IA: la eficiencia del contexto. Al combinar la familiaridad de YAML y CSV con guardrails estructurales que los LLMs pueden validar, logra reducir tokens significativamente sin sacrificar legibilidad ni precisión.</p><p>Para aquellos de nosotros que hacemos vibecoding de forma intensiva, TOON es una herramienta más en el arsenal de optimización. No es magia: requiere que tus datos tengan cierta uniformidad para aprovechar al máximo el formato tabular. Pero cuando tus casos de uso encajan, los ahorros del 30-60% en tokens se traducen directamente en más contexto disponible, menos límites alcanzados, y menores costos de API.</p><p>El formato está en producción pero sigue evolucionando. Si trabajas con grandes volúmenes de datos estructurados en tus prompts de LLM, vale la pena experimentar con TOON y ver cómo impacta tu flujo de trabajo específico.</p></article>",
  "metadata": {
    "created_time": "2025-11-19T12:00:00Z",
    "modification_time": "2025-11-19T19:08:26.019Z",
    "version": "1.0",
    "status": "published",
    "seo_keywords": "toon, token-oriented object notation, context compression, llm tokens, json alternative, yaml csv hybrid, ai coding optimization, prompt engineering, token efficiency, vibecoding, cost optimization, deepseek, claude haiku"
  },
  "featured": true,
  "views": 5
}